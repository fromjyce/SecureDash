{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17j3WcQ8F8mUwRvbbcjCopcrlBF19pBZq","authorship_tag":"ABX9TyP7PNw4/3q+XvN82VF0DYsI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow==2.16.1\n","!pip install keras==3.3.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mYUPluVDC9t","executionInfo":{"status":"ok","timestamp":1717002365729,"user_tz":-330,"elapsed":164433,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}},"outputId":"27aa06f4-d5ee-4fd7-848a-e4d5095e32b7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.16.1\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow==2.16.1)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.64.0)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow==2.16.1)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n","Requirement already satisfied: keras==3.3.3 in /usr/local/lib/python3.10/dist-packages (3.3.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (1.25.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.3.3) (0.3.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.3.3) (4.11.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.3.3) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.3.3) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.3.3) (0.1.2)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"Keras version:\", keras.__version__)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuZ1l1OECJlx","executionInfo":{"status":"ok","timestamp":1717002370736,"user_tz":-330,"elapsed":5022,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}},"outputId":"0c1557bb-f1c2-4de4-9fca-c4ee4e9ff351"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.16.1\n","Keras version: 3.3.3\n"]}]},{"cell_type":"code","source":["#Libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import files\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GRU, Dropout, Dense, Flatten, Concatenate\n","import matplotlib.pyplot as plt"],"metadata":{"id":"iqTzWH77ROvd","executionInfo":{"status":"ok","timestamp":1717002371193,"user_tz":-330,"elapsed":461,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Datasets/03-11/ALL.xlsx\")"],"metadata":{"id":"n83J87-hRhAK","executionInfo":{"status":"ok","timestamp":1717003123547,"user_tz":-330,"elapsed":752357,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data['Label'] = data['Label'].map({'Attack': 0, 'Benign': 1})"],"metadata":{"id":"LLNDVBeVWI6c","executionInfo":{"status":"ok","timestamp":1717003124251,"user_tz":-330,"elapsed":709,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["X = data.drop(columns=['Label'])\n","sc = StandardScaler()\n","rescaled = sc.fit_transform(X)\n","y = data['Label']"],"metadata":{"id":"m_5CX_nbWcDm","executionInfo":{"status":"ok","timestamp":1717003126503,"user_tz":-330,"elapsed":2256,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from imblearn.over_sampling import ADASYN\n","\n","ada = ADASYN(sampling_strategy='auto', random_state=42)\n","new_x, new_y = ada.fit_resample(rescaled, y)"],"metadata":{"id":"sSAKb60lYucy","executionInfo":{"status":"ok","timestamp":1717003657673,"user_tz":-330,"elapsed":531175,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","counter_bef = Counter(y)\n","print(\"Before\", counter_bef)\n","\n","counter_aft = Counter(new_y)\n","print(\"Before\", counter_aft)\n"],"metadata":{"id":"wPTt92DLZA-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717003657674,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}},"outputId":"c426e753-9e5a-44d6-c96f-4bf3d3e484cf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Before Counter({0: 332855, 1: 93411})\n","Before Counter({0: 332855, 1: 332625})\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(new_x, new_y, test_size=0.33, random_state=42)"],"metadata":{"id":"lguukKoBWA8s","executionInfo":{"status":"ok","timestamp":1717003658388,"user_tz":-330,"elapsed":719,"user":{"displayName":"Mahesh K","userId":"06829212588440351374"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Define input shape\n","input_shape = (X_train.shape[1], 1)  # Assuming X_train is defined somewhere in your script\n","\n","# Define the input layer\n","inputs = Input(shape=input_shape)\n","\n","# Convolutional layers\n","x = inputs\n","for _ in range(4):\n","    x = Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","# Flatten CNN output\n","cnn_out = Flatten()(x)\n","\n","# GRU layers need to operate on sequences, so we need to prepare a sequence input\n","# Let's assume we reshape the same input for the GRU path, you might need to adjust this\n","y = Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape)(inputs)\n","y = MaxPooling1D(pool_size=2)(y)\n","for _ in range(2):\n","    y = GRU(units=64, activation='tanh', return_sequences=True)(y)\n","# Last GRU layer should not return sequences to match the flatten layer\n","gru_out = GRU(units=64, activation='tanh')(y)\n","\n","# Concatenate CNN and GRU outputs\n","merged = Concatenate()([cnn_out, gru_out])\n","\n","# Additional layers\n","x = Dense(units=64, activation='relu')(merged)\n","x = Dropout(0.5)(x)\n","outputs = Dense(units=2, activation='softmax')(x)  # Softmax for classification\n","\n","# Create and compile model\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Reshape input data to fit the model\n","X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","# Train the model\n","history = model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n","\n","model.save('IDS_Model.h5')\n","files.download('IDS_Model.h5')\n","\n","\n","plt.style.use('dark_background')\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(1, 2, 1)\n","plt.suptitle('Optimizer : Adam', fontsize=10)\n","plt.ylabel('Loss', fontsize=16)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend(loc='upper right')\n","\n","plt.subplot(1, 2, 2)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2B900tQzmC7n","outputId":"68980d5c-daeb-4f26-d492-69407aefaa68"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1740s\u001b[0m 124ms/step - accuracy: 0.9887 - loss: 0.0409 - val_accuracy: 0.9962 - val_loss: 0.0170\n","Epoch 2/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1683s\u001b[0m 121ms/step - accuracy: 0.9967 - loss: 0.0159 - val_accuracy: 0.9955 - val_loss: 0.0204\n","Epoch 3/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1617s\u001b[0m 116ms/step - accuracy: 0.9970 - loss: 0.0148 - val_accuracy: 0.9973 - val_loss: 0.0133\n","Epoch 4/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1649s\u001b[0m 117ms/step - accuracy: 0.9971 - loss: 0.0143 - val_accuracy: 0.9971 - val_loss: 0.0145\n","Epoch 5/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1528s\u001b[0m 108ms/step - accuracy: 0.9969 - loss: 0.0149 - val_accuracy: 0.9973 - val_loss: 0.0142\n","Epoch 6/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1563s\u001b[0m 112ms/step - accuracy: 0.9970 - loss: 0.0151 - val_accuracy: 0.9975 - val_loss: 0.0120\n","Epoch 7/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1625s\u001b[0m 117ms/step - accuracy: 0.9971 - loss: 0.0132 - val_accuracy: 0.9974 - val_loss: 0.0134\n","Epoch 8/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1587s\u001b[0m 113ms/step - accuracy: 0.9971 - loss: 0.0170 - val_accuracy: 0.9972 - val_loss: 0.0141\n","Epoch 9/10\n","\u001b[1m13934/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1637s\u001b[0m 117ms/step - accuracy: 0.9971 - loss: 0.0138 - val_accuracy: 0.9975 - val_loss: 0.0120\n","Epoch 10/10\n","\u001b[1m13595/13934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.9970 - loss: 0.0151"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Assuming history is obtained from the model.fit function\n","# Set the style of matplotlib to 'ggplot' for better visuals\n","plt.style.use('ggplot')\n","\n","# Create a figure and a set of subplots\n","plt.figure(figsize=(14, 6))\n","\n","# Plot training and validation loss\n","plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot training and validation accuracy\n","plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Show the plots\n","plt.show()\n"],"metadata":{"id":"BPUsXV6C-R5z"},"execution_count":null,"outputs":[]}]}